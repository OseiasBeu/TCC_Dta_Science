# -*- coding: utf-8 -*-
"""Twitter_API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h_0m0M9oIG7kNZ7T9Wvv0dyAeMcl_y_0
"""

import tweepy as tw
import pandas as pd

# with open('twitter-tokens.txt', 'r') as tfile:
#     consumer_key = tfile.readline().strip('\n')
#     consumer_secret = tfile.readline().strip('\n')
#     access_token = tfile.readline().strip('\n')
#     access_token_secret = tfile.readline().strip('\n')

auth = tw.AppAuthHandler(consumer_key, consumer_secret)

api = tw.API(auth)
# print(api)
query_search= "Bolsonaro"  + " -filter:retweets"
cursor_tweets = tw.Cursor(api.search,q=query_search).items(100)
for tweet in cursor_tweets:
  print(tweet.text)

twkeys = tweet._json.keys()

twkeys

tweets_dict = {}
tweets_dict = tweets_dict.fromkeys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted'])

tweets_dict

query_search= "#almanara"  + " -filter:retweets" 
cursor_tweets = tw.Cursor(api.search,
                          since="2021-07-10",
                          # until="2021-07-25",
            q=query_search).items(200)

# print(len(cursor_tweets))

# for tweet in cursor_tweets:
#   print(tweet.text)

for tweet in cursor_tweets:
  for key in tweets_dict.keys():
    try:
      twvalue = tweet._json[key]
      tweets_dict[key].append(twvalue)
    except KeyError:
      twvalue = ""
      if (tweets_dict[key] is None):
        tweets_dict[key] = [twvalue]
      else:
        tweets_dict[key].append(twvalue)
    except:
      tweets_dict[key] = [twvalue]
    # print("tweets_dict[key]: {} - tweet[key]: {}".format(tweets_dict[key],  twvalue))

# tweets_dict

dfTweets = pd.DataFrame.from_dict(tweets_dict)

# dfTweets.head()
dfTweets.to_csv('teste.csv',sep=';')

dfTweets.shape

import csv
import nltk
from nltk.tokenize import word_tokenize 
from wordcloud import WordCloud
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

nltk.download()

dfTweets['tokenized_text'] = dfTweets.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)

stopwords = nltk.corpus.stopwords.words('portuguese')

#Bolsonaro
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#Lula
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#Genocida
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#ladr√£o
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#Samsung a20
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#Wendell Lima
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

#Almanara
text = dfTweets.tokenized_text
wordcloud = WordCloud(
    width = 3000,
    height = 2000,
    background_color = 'white',
    stopwords=stopwords).generate(str(text))
fig = plt.figure(
    figsize = (40, 30),
    facecolor = 'k',
    edgecolor = 'k')
plt.imshow(wordcloud, interpolation = 'bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

