{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline_data_mining.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsflWhF3JD3Bh9i1CGY/KP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OseiasBeu/TCC_Dta_Science/blob/main/pipeline_data_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3bKils3q7Wc"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qhcB4vmhKr"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import brown\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGYXSe6KpV8L",
        "outputId": "8179dc72-c7d4-43ae-c14c-0432f16ef62d"
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixoqkYlqqtZJ"
      },
      "source": [
        "## Entrada de dados! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F16flFurO4z"
      },
      "source": [
        "É nessa parte do script por onde as API's serão consultadas e as bases serão lidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkjKGD8zpneb"
      },
      "source": [
        "file = 'https://raw.githubusercontent.com/OseiasBeu/TCC_Dta_Science/main/datasets/news.csv'\n",
        "dataBase = pd.read_csv(file, sep=';', header=None)\n",
        "df = pd.DataFrame(dataBase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X8nsOJer1OI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7076bfe-1f64-48d7-e439-467c8d1023bf"
      },
      "source": [
        "print(df.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   0           1\n",
            "0  O capitão américa aparece sobrevoando São Paul...  verdadeiro\n",
            "1       A polarização da população gera guerra civil   fake_news\n",
            "2  O Chaves se pronuncia e diz está indignado com...  verdadeiro\n",
            "3    Morte do precidenciavel X por acidente de aviao  verdadeiro\n",
            "4  Monumento de Brasilia é atacado por manifestan...   fake_news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erZPdAU53DkZ"
      },
      "source": [
        "## Verificando a frequência das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku_rUivS21jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb6fd9d-6d77-4be1-fc2e-fc8acabfc014"
      },
      "source": [
        "lista_de_frases = df[0].to_list()\n",
        "lista_de_palavras = []\n",
        "for x in lista_de_frases:\n",
        "  lista_de_palavras += x.split()\n",
        "print(lista_de_palavras)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'capitão', 'américa', 'aparece', 'sobrevoando', 'São', 'Paulo', 'e', 'diz', 'que', 'irá', 'se', 'candidatar', 'A', 'polarização', 'da', 'população', 'gera', 'guerra', 'civil', 'O', 'Chaves', 'se', 'pronuncia', 'e', 'diz', 'está', 'indignado', 'com', 'tanta', 'mentira.', 'Morte', 'do', 'precidenciavel', 'X', 'por', 'acidente', 'de', 'aviao', 'Monumento', 'de', 'Brasilia', 'é', 'atacado', 'por', 'manifestantes', 'e', 'eleicoes', 'seráo', 'canceladas', 'Novo', 'presidente', 'se', 'diz', 'confiante', 'para', 'governar', 'o', 'pais', 'Jair', 'Bolsonaro', 'sobe', 'no', 'ranking', 'de', 'rejeicao', 'no', 'nordeste', 'Haddad', 'melhora', 'nas', 'pesquisas', 'apos', 'apoio', 'de', 'Lula', 'Disputa', 'no', 'segundo', 'turno', 'está', 'cada', 'vez', 'mais', 'acirrada', 'entre', 'os', 'extremos', 'Amoedo', 'declara', 'apoio', 'ao', 'PT', 'Manifestantes', 'em', 'Sao', 'Paulo', 'param', 'avenida', 'pedem', 'intervençao', 'militar!', 'Padre', 'Marcelo', 'Rossi', 'diz', 'que', 'irá', 'se', 'candidatar', 'a', 'presidencia', 'Ex', 'presidente', 'Lula', 'consegue', 'habeas', 'Corpus', 'e', 'pode', 'ser', 'candidato', 'Presidente', 'temmer', 'declara', 'apoio', 'ao', 'partido', 'NOVO', 'Mourao', 'declara', 'que', 'é', 'contra', 'o', '13', 'salario', 'e', 'adiantamento', 'de', 'férias', 'de', 'funcionários']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOaT5NuV3WMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca10b09-f082-4d75-ea5a-fcd9eaa845de"
      },
      "source": [
        "frequencia_de_palavras = FreqDist(lista_de_palavras)\n",
        "frequencia_de_palavras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'13': 1,\n",
              "          'A': 1,\n",
              "          'Amoedo': 1,\n",
              "          'Bolsonaro': 1,\n",
              "          'Brasilia': 1,\n",
              "          'Chaves': 1,\n",
              "          'Corpus': 1,\n",
              "          'Disputa': 1,\n",
              "          'Ex': 1,\n",
              "          'Haddad': 1,\n",
              "          'Jair': 1,\n",
              "          'Lula': 2,\n",
              "          'Manifestantes': 1,\n",
              "          'Marcelo': 1,\n",
              "          'Monumento': 1,\n",
              "          'Morte': 1,\n",
              "          'Mourao': 1,\n",
              "          'NOVO': 1,\n",
              "          'Novo': 1,\n",
              "          'O': 2,\n",
              "          'PT': 1,\n",
              "          'Padre': 1,\n",
              "          'Paulo': 2,\n",
              "          'Presidente': 1,\n",
              "          'Rossi': 1,\n",
              "          'Sao': 1,\n",
              "          'São': 1,\n",
              "          'X': 1,\n",
              "          'a': 1,\n",
              "          'acidente': 1,\n",
              "          'acirrada': 1,\n",
              "          'adiantamento': 1,\n",
              "          'américa': 1,\n",
              "          'ao': 2,\n",
              "          'aparece': 1,\n",
              "          'apoio': 3,\n",
              "          'apos': 1,\n",
              "          'atacado': 1,\n",
              "          'avenida': 1,\n",
              "          'aviao': 1,\n",
              "          'cada': 1,\n",
              "          'canceladas': 1,\n",
              "          'candidatar': 2,\n",
              "          'candidato': 1,\n",
              "          'capitão': 1,\n",
              "          'civil': 1,\n",
              "          'com': 1,\n",
              "          'confiante': 1,\n",
              "          'consegue': 1,\n",
              "          'contra': 1,\n",
              "          'da': 1,\n",
              "          'de': 6,\n",
              "          'declara': 3,\n",
              "          'diz': 4,\n",
              "          'do': 1,\n",
              "          'e': 5,\n",
              "          'eleicoes': 1,\n",
              "          'em': 1,\n",
              "          'entre': 1,\n",
              "          'está': 2,\n",
              "          'extremos': 1,\n",
              "          'funcionários': 1,\n",
              "          'férias': 1,\n",
              "          'gera': 1,\n",
              "          'governar': 1,\n",
              "          'guerra': 1,\n",
              "          'habeas': 1,\n",
              "          'indignado': 1,\n",
              "          'intervençao': 1,\n",
              "          'irá': 2,\n",
              "          'mais': 1,\n",
              "          'manifestantes': 1,\n",
              "          'melhora': 1,\n",
              "          'mentira.': 1,\n",
              "          'militar!': 1,\n",
              "          'nas': 1,\n",
              "          'no': 3,\n",
              "          'nordeste': 1,\n",
              "          'o': 2,\n",
              "          'os': 1,\n",
              "          'pais': 1,\n",
              "          'para': 1,\n",
              "          'param': 1,\n",
              "          'partido': 1,\n",
              "          'pedem': 1,\n",
              "          'pesquisas': 1,\n",
              "          'pode': 1,\n",
              "          'polarização': 1,\n",
              "          'população': 1,\n",
              "          'por': 2,\n",
              "          'precidenciavel': 1,\n",
              "          'presidencia': 1,\n",
              "          'presidente': 2,\n",
              "          'pronuncia': 1,\n",
              "          'que': 3,\n",
              "          'ranking': 1,\n",
              "          'rejeicao': 1,\n",
              "          'salario': 1,\n",
              "          'se': 4,\n",
              "          'segundo': 1,\n",
              "          'ser': 1,\n",
              "          'seráo': 1,\n",
              "          'sobe': 1,\n",
              "          'sobrevoando': 1,\n",
              "          'tanta': 1,\n",
              "          'temmer': 1,\n",
              "          'turno': 1,\n",
              "          'vez': 1,\n",
              "          'é': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvelEzvb49ST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08ab6359-f4af-4d7a-c203-87c433c96a97"
      },
      "source": [
        "frequencia_de_palavras.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'de'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt8x7wJX5NcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a3553f-0c71-4ee6-8cf5-6a97c48efb6b"
      },
      "source": [
        "frequencia_de_palavras.items()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('O', 2), ('capitão', 1), ('américa', 1), ('aparece', 1), ('sobrevoando', 1), ('São', 1), ('Paulo', 2), ('e', 5), ('diz', 4), ('que', 3), ('irá', 2), ('se', 4), ('candidatar', 2), ('A', 1), ('polarização', 1), ('da', 1), ('população', 1), ('gera', 1), ('guerra', 1), ('civil', 1), ('Chaves', 1), ('pronuncia', 1), ('está', 2), ('indignado', 1), ('com', 1), ('tanta', 1), ('mentira.', 1), ('Morte', 1), ('do', 1), ('precidenciavel', 1), ('X', 1), ('por', 2), ('acidente', 1), ('de', 6), ('aviao', 1), ('Monumento', 1), ('Brasilia', 1), ('é', 2), ('atacado', 1), ('manifestantes', 1), ('eleicoes', 1), ('seráo', 1), ('canceladas', 1), ('Novo', 1), ('presidente', 2), ('confiante', 1), ('para', 1), ('governar', 1), ('o', 2), ('pais', 1), ('Jair', 1), ('Bolsonaro', 1), ('sobe', 1), ('no', 3), ('ranking', 1), ('rejeicao', 1), ('nordeste', 1), ('Haddad', 1), ('melhora', 1), ('nas', 1), ('pesquisas', 1), ('apos', 1), ('apoio', 3), ('Lula', 2), ('Disputa', 1), ('segundo', 1), ('turno', 1), ('cada', 1), ('vez', 1), ('mais', 1), ('acirrada', 1), ('entre', 1), ('os', 1), ('extremos', 1), ('Amoedo', 1), ('declara', 3), ('ao', 2), ('PT', 1), ('Manifestantes', 1), ('em', 1), ('Sao', 1), ('param', 1), ('avenida', 1), ('pedem', 1), ('intervençao', 1), ('militar!', 1), ('Padre', 1), ('Marcelo', 1), ('Rossi', 1), ('a', 1), ('presidencia', 1), ('Ex', 1), ('consegue', 1), ('habeas', 1), ('Corpus', 1), ('pode', 1), ('ser', 1), ('candidato', 1), ('Presidente', 1), ('temmer', 1), ('partido', 1), ('NOVO', 1), ('Mourao', 1), ('contra', 1), ('13', 1), ('salario', 1), ('adiantamento', 1), ('férias', 1), ('funcionários', 1)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fsM0hA75Tgy"
      },
      "source": [
        "## Removendo a stop_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-AulIhT5Qn8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}